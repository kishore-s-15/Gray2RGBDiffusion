# Gray2RGB Diffusion - Image Colorization using Diffusion Models

This repository implements image colorization using a diffusion-based approach inspired by the paper **"Palette:
Image-to-Image Diffusion Models"**. The model is trained to predict the colorized version of grayscale images. Due to
computational constraints, the model has been trained on **32x32** images from the CIFAR-10 dataset.

---

## ğŸ“œ Reference

- **Paper**: [Palette: Image-to-Image Diffusion Models](https://arxiv.org/abs/2111.05826)

---

## ğŸ–¼ï¸ Dataset

The CIFAR-10 dataset is used for training and evaluation. Images are resized to **32x32** for computational efficiency.

---

## ğŸš€ Features

- **Diffusion-based Colorization**: Utilizes a diffusion process to progressively denoise grayscale images into
  colorized outputs.
- **Customizable Configurations**: Adjust model architecture, training parameters, and dataset preprocessing via
  configuration files.
- **Efficient Training**: Supports training on smaller image sizes for resource-constrained environments.

---

## ğŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/kishore-s-15/Gray2RGBDiffusion.git
   cd Gray2RGBDiffusion
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ‹ï¸â€â™‚ï¸ How to Train

To train the model, use the training script:
```bash
python gray2rgb_diffusion/scripts/train_script.py
```

### âš™ï¸ Training Configuration

The training parameters (batch size, learning rate, etc.) are defined in `configs/config.py`. You can modify them as
needed.

---

## ğŸ§ª How to Run Inference

To perform inference and visualize results:

```bash
python gray2rgb_diffusion/scripts/inference_script.py
```

### ğŸ§¹ Outputs

![Colorization.png](gray2rgb_diffusion/imgs/colorization.png)

---

## ğŸ“Š Results

Due to training on smaller images (32x32), the results are limited compared to the full implementation in the original
paper. However, this implementation demonstrates the potential of diffusion-based models for image colorization.

| Metrics                     | Scores |
|-----------------------------|--------|
| FrÃ©chet Inception Distance  | 10.6   |
| Inception Score            | 198.3  |

---

## ğŸ“‚ File Structure

```plaintext
â”œâ”€â”€ configs/                # Configuration files
â”‚   â””â”€â”€ config.py           # Training and inference parameters
â”œâ”€â”€ data/                   # Dataset-related scripts
â”‚   â””â”€â”€ dataset.py          # Custom CIFAR-10 dataset with grayscale preprocessing
â”œâ”€â”€ evaluation/             # Generated Images Evaluation related scripts
â”‚   â””â”€â”€ evaluations.py      # FrÃ©chet inception distance and Inception score metrics
â”œâ”€â”€ inference/              # Inference-related scripts
â”‚   â””â”€â”€ infer.py            # File consists of code for generating new images
â”œâ”€â”€ models/                 # Model architecture and utilities
â”‚   â”œâ”€â”€ model.py            # UNet2D model definition
â”‚   â””â”€â”€ save_model.py       # Model save/load functions
â”œâ”€â”€ scripts/                # Training and inference scripts
â”‚   â”œâ”€â”€ train_script.py     # Training pipeline
â”‚   â””â”€â”€ inference_script.py # Inference pipeline
â”œâ”€â”€ training/               # Training-related scripts
â”‚   â””â”€â”€ train.py            # File consists of code for training the diffusion model
â”œâ”€â”€ utils/                  # Helper functions
â”‚   â””â”€â”€ transforms.py       # Preprocessing and reverse transforms
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ“§ Contact

For questions or issues, feel free to open a GitHub issue.

- Kishore Sampath, sampath.ki@northeastern.edu
- Pratheesh, lnu.prat@northeastern.edu
